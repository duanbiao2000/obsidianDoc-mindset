好的，遵照您的要求，這就利用符號改寫法對筆記 [[机器学习算法]] 進行優化。

---

### **[[机器学习算法]] (符號優化版)**

#### **一、學習範式 (The "Why")**

| 範式 | 代表算法 | 核心思想 | 類比 |
| :--- | :--- | :--- | :--- |
| **監督學習** | 線性回歸、SVM、神經網絡 | 從**有標籤**數據中學習輸入→輸出的映射。 | 老師給例題和答案，你學習解題方法。 |
| **無監督學習** | K-Means、PCA | 從**無標籤**數據中發現內在結構、模式。 | 在圖書館自行對書籍分類，發現結構。 |
| **強化學習** | Q-Learning、DQN | 通過**試錯**，最大化長期累積獎勵。 | 玩遊戲，通過操作(行動)→分數(獎勵)，學習最優策略。 |
| **自監督學習** | BERT、SimCLR | 從無標籤數據中**構造**監督信號，學習通用表示。 | 通過填空題學習語言。自己出題自己做。 |
| **半監督學習** | Label Propagation | 利用**少量標籤+大量無標籤**數據學習。 | 少數精英指導 + 大眾行為觀察，共同學習。 |
| **聯邦學習** | FedAvg | 在**數據不集中**的情況下進行分佈式訓練，保護隱私。 | 不同學校學生各自學習，定期上交成果(參數)，但個人筆記(數據)不公開。 |

---

#### **二、神經網絡架構 (The "How" - Micro)**

| 類型 | 特點 | 應用 | 認知類比 |
| :--- | :--- | :--- | :--- |
| **MLP** | 多層全連接。 | 結構化數據，簡單模式識別。 | 基礎信息傳遞模型，△ 缺乏對數據空間結構的感知。 |
| **CNN** | **卷積**核實現局部感知+權重共享，**池化**降分辨率+增強不變性。 | 圖像識別、語音識別。 | 受視覺皮層啟發，擅長識別局部模式 (如邊緣)。 |
| **RNN/LSTM** | **循環**結構處理序列，利用**記憶**保存歷史信息。 | 時間序列預測、NLP。 | 模擬序列信息處理，△ LSTM/GRU通過門控機制改善長距離依賴問題。 |
| **Transformer**| 基於 **Self-Attention**，並行處理序列中任意位置的關係。 | NLP (LLM)、視覺。 | △ 不依賴順序，能並行關注任意重要信息，構建全面的“上下文理解”。 |
| **GNN** | 直接作用於**圖**結構數據，通過節點間信息聚合學習。 | 知識圖譜、推薦系統。 | 擅長處理具有複雜關係的非歐氏數據。 |

---

#### **三、算法的選擇 (The "When/Where")**

△ 沒有“萬能藥”，只有最適合特定問題和約束條件的算法。

| 類型 | 訓練速度 | 泛化能力 | 可解釋性 | 對數據要求 | 適用任務 | 選擇考量 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **決策樹** | 快 | 中 | **強** | 低 | 分類/回歸 | 需要理解決策路徑時首選；△ 易過擬合 (需剪枝)。 |
| **神經網絡** | **慢** | **強** | **弱** | 大數據 | 複雜模式識別 | 數據量大，計算資源足，不強求可解釋性時首選。 |
| **SVM** | 中 | 中 | 中 | 特徵縮放重要 | 小樣本、高維分類 | 數據量不大，特徵維度高時考慮。 |
| **KNN** | 無訓練 | 弱 | **強** | 對噪聲敏感 | 實時推薦 | 數據量不大，對計算效率要求不高時考慮。 |
| **Boosting** | 中 | **強** | 中 | 調參重要 | 高性能tabular任務 | 追求高精度，願意投入調參精力時首選；△ 對異常值敏感。 |
| **GNN** | 中 | **強** | **弱** | 圖結構數據 | 關係建模 | 數據天然是圖結構時首選。 |

---

#### **四、系統性解構 (元分析)**

1.  **分解軸線**:
    *   **按學習範式 (Why)**: 哲學與數據依賴性。
    *   **按解決任務 (What)**: 功能性目標。
    *   **按組合策略 (How - Meta)**: 組件如何集成。
    *   **按內部架構 (How - Micro)**: 結構如何適配數據。
    *   **按決策約束 (When/Where)**: 現實世界約束下的選擇。

2.  **關鍵關係**:
    *   **層級依賴**: 範式 → 任務 → 算法 (決策路徑)。
    *   **組合關係**: 基學習器 → 集成學習器 (魯棒性↑)。
    *   **適配關係**: 數據結構 → 網絡架構 (架構與信息拓撲的對齊)。
    *   **權衡關係**: 性能 ↔ 資源 ↔ 可解釋性 (多目標優化)。

3.  **更大系統中的位置**:
    *   算法選擇是**端到端ML價值鏈**中的一個決策節點。
    *   **價值鏈**: 問題定義 → 數據工程 → **模型開發 (本筆記)** → 模型評估 → 部署 → 持續監控。

4.  **變化影響**:
    *   **新算法出現**: 可能改變上下游要求，打破現有“路徑依賴”。
    *   **範式轉變 (如自監督↑)**: 系統級躍遷，可能重塑數據戰略和成本結構。
    *   **外部約束變化 (如法規要求可解釋性↑)**: 改變算法選擇矩陣的權重，強制系統向不同技術路徑收斂。

**總結**: 這篇筆記是一次成功的**路徑壓縮**實踐，將複雜的ML領域壓縮為一個結構化的、可供導航和決策的知識系統。